{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NWS Forecast Data\n",
    "\n",
    "This notebook explains how to scrape, transform, and upload the NWS's hourly weather forecast for the next 6 days** into a dataset in BigQuery. The resulting script can be set to run at regular intervals as an Airflow DAG or a function in Cloud Functions. \n",
    "\n",
    "** *For some reason, the hourly forecast doesn't quite extend to a full week, but only 6.5 days. To keep the math easier, we will only scrape the next 6 days -- in the end, this won't affect our pipeline once we have it updating continuously.*\n",
    "\n",
    "We will collect hourly forecasts for the locations of 23 USCRN data collection stations in Alaska -- the presence of these stations will enable ourselves and any other users of our dataset to evaluate the accuracy of the forecasts.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why use scraping over `api.weather.gov`?\n",
    "\n",
    "Generally speaking, if a website offers an API to access its data then it's a good bet to use it. So why not just use `api.weather.gov`?\n",
    "\n",
    "There are at least twi reasons I chose to webscrape the forecast data for this project:\n",
    "\n",
    "1. I've noticed at times that the `api.weather.gov` can give a `500: Internal Server Error` response when the HTML data interface is still accessible.  \n",
    "2. As far as I can tell, the API does not offer the same amount of information as the tabular HTML interface:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import datetime as dt \n",
    "import itertools\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df = pd.read_csv(\"../data/locations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station_location    Toolik_Lake\n",
      "wbanno                    96409\n",
      "longitude                -149.4\n",
      "latitude                  68.65\n",
      "Name: 20, dtype: object\n",
      "\n",
      "{'number': 1, 'name': '', 'startTime': '2023-02-27T20:00:00-09:00', 'endTime': '2023-02-27T21:00:00-09:00', 'isDaytime': False, 'temperature': -7, 'temperatureUnit': 'F', 'temperatureTrend': None, 'probabilityOfPrecipitation': {'unitCode': 'wmoUnit:percent', 'value': 1}, 'dewpoint': {'unitCode': 'wmoUnit:degC', 'value': -25}, 'relativeHumidity': {'unitCode': 'wmoUnit:percent', 'value': 77}, 'windSpeed': '10 mph', 'windDirection': 'SW', 'icon': 'https://api.weather.gov/icons/land/night/bkn,1?size=small', 'shortForecast': 'Mostly Cloudy', 'detailedForecast': ''}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Date</td>\n",
       "      <td>02/27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hour (AKST)</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>00</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>03</td>\n",
       "      <td>04</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Temperature (°F)</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>-10</td>\n",
       "      <td>-11</td>\n",
       "      <td>-12</td>\n",
       "      <td>-13</td>\n",
       "      <td>-13</td>\n",
       "      <td>-13</td>\n",
       "      <td>-14</td>\n",
       "      <td>...</td>\n",
       "      <td>-12</td>\n",
       "      <td>-12</td>\n",
       "      <td>-11</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "      <td>-9</td>\n",
       "      <td>-7</td>\n",
       "      <td>-6</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dewpoint (°F)</td>\n",
       "      <td>-16</td>\n",
       "      <td>-15</td>\n",
       "      <td>-17</td>\n",
       "      <td>-19</td>\n",
       "      <td>-21</td>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-22</td>\n",
       "      <td>-23</td>\n",
       "      <td>...</td>\n",
       "      <td>-20</td>\n",
       "      <td>-20</td>\n",
       "      <td>-19</td>\n",
       "      <td>-19</td>\n",
       "      <td>-18</td>\n",
       "      <td>-17</td>\n",
       "      <td>-16</td>\n",
       "      <td>-15</td>\n",
       "      <td>-13</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wind Chill (°F)</td>\n",
       "      <td>-25</td>\n",
       "      <td>-27</td>\n",
       "      <td>-28</td>\n",
       "      <td>-29</td>\n",
       "      <td>-33</td>\n",
       "      <td>-33</td>\n",
       "      <td>-33</td>\n",
       "      <td>-33</td>\n",
       "      <td>-34</td>\n",
       "      <td>...</td>\n",
       "      <td>-33</td>\n",
       "      <td>-33</td>\n",
       "      <td>-33</td>\n",
       "      <td>-32</td>\n",
       "      <td>-31</td>\n",
       "      <td>-30</td>\n",
       "      <td>-28</td>\n",
       "      <td>-26</td>\n",
       "      <td>-25</td>\n",
       "      <td>-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Surface Wind (mph)</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wind Dir</td>\n",
       "      <td>SW</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gust</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sky Cover (%)</td>\n",
       "      <td>67</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Precipitation Potential (%)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Relative Humidity (%)</td>\n",
       "      <td>71</td>\n",
       "      <td>75</td>\n",
       "      <td>71</td>\n",
       "      <td>68</td>\n",
       "      <td>65</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Rain</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Thunder</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Snow</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Freezing Rain</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>...</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0      1    2    3    4      5    6    7    8   \\\n",
       "1                          Date  02/27  NaN  NaN  NaN  02/28  NaN  NaN  NaN   \n",
       "2                   Hour (AKST)     20   21   22   23     00   01   02   03   \n",
       "3              Temperature (°F)     -9   -9  -10  -11    -12  -13  -13  -13   \n",
       "4                 Dewpoint (°F)    -16  -15  -17  -19    -21  -22  -22  -22   \n",
       "5               Wind Chill (°F)    -25  -27  -28  -29    -33  -33  -33  -33   \n",
       "6            Surface Wind (mph)      8    9    9    9     11   11   11   11   \n",
       "7                      Wind Dir     SW    S    S    S      S    S    S    S   \n",
       "8                          Gust    NaN  NaN  NaN  NaN    NaN  NaN  NaN  NaN   \n",
       "9                 Sky Cover (%)     67   59   59   59      3    3    3    1   \n",
       "10  Precipitation Potential (%)      1    1    1    1      1    1    1    1   \n",
       "11        Relative Humidity (%)     71   75   71   68     65   63   62   62   \n",
       "12                         Rain     --   --   --   --     --   --   --   --   \n",
       "13                      Thunder     --   --   --   --     --   --   --   --   \n",
       "14                         Snow     --   --   --   --     --   --   --   --   \n",
       "15                Freezing Rain     --   --   --   --     --   --   --   --   \n",
       "\n",
       "     9   ...   15   16   17   18   19   20   21   22   23   24  \n",
       "1   NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2    04  ...   10   11   12   13   14   15   16   17   18   19  \n",
       "3   -14  ...  -12  -12  -11  -10  -10   -9   -7   -6   -4   -3  \n",
       "4   -23  ...  -20  -20  -19  -19  -18  -17  -16  -15  -13  -12  \n",
       "5   -34  ...  -33  -33  -33  -32  -31  -30  -28  -26  -25  -24  \n",
       "6    11  ...   13   13   14   14   14   14   14   14   15   15  \n",
       "7     S  ...    S    S    S    S    S    S    S    S    S    S  \n",
       "8   NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "9     1  ...    6    6   21   21   21   45   45   45   80   80  \n",
       "10    1  ...    1    1    1    1    1    3    3    3   10   10  \n",
       "11   62  ...   66   66   66   66   66   66   66   65   66   67  \n",
       "12   --  ...   --   --   --   --   --   --   --   --   --   --  \n",
       "13   --  ...   --   --   --   --   --   --   --   --   --   --  \n",
       "14   --  ...   --   --   --   --   --   --   --   --   --   --  \n",
       "15   --  ...   --   --   --   --   --   --   --   --   --   --  \n",
       "\n",
       "[15 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_location = locations_df.sample(1).iloc[0] \n",
    "\n",
    "print(f\"{random_location}\\n\")\n",
    "\n",
    "lat, lon = random_location['latitude'], random_location['longitude']  \n",
    "\n",
    "## API results\n",
    "url = f\"https://api.weather.gov/points/{lat},{lon}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "main_data = response.json()\n",
    "\n",
    "response = requests.get(main_data['properties']['forecastHourly'])\n",
    "hourly_data = response.json()\n",
    "fields = hourly_data['properties']['periods'][0]\n",
    "\n",
    "print(f\"{fields}\\n\") \n",
    "\n",
    "## Webscraping results \n",
    "url = f\"https://forecast.weather.gov/MapClick.php?lat={lat}&lon={lon}&unit=0&lg=english&FcstType=digital&menu=1\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "df = pd.read_html(str(soup.find_all(\"table\")[5]))[0]\n",
    "df = df.iloc[1:16,:]\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results need cleaning (e.g. the column names are in the first row), but you can see that (almost) all the same information is present with the addition of several other fields. The sole exception is `isDaytime` field: depending on how `isDaytime` is measured, it might be more accurate than any estimate of daylight hours we could make based off the scraped data. \n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.) Scraping the Data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each location, the forecast for the next 48 hours is stored in a tabular data table like this: \n",
    "\n",
    "<img src=\"../img/nws_p1.png\" height=400px>\n",
    "\n",
    "The rest of the forecast can be accessed by jumping ahead in 48 hour increments. We do this by adding `&AheadHour=` on the end of the URL and specifying how many hours (48 and 96). \n",
    "\n",
    "The series of transformations required here is quite complex -- a downside of scraping vs using the API -- so I've broken it up into many modular functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General Utilities \n",
    "def get_soup(url:str) -> BeautifulSoup:\n",
    "  \"\"\"Simple wrapper for getting beautiful soup object from url\"\"\"\n",
    "  result = requests.get(url)\n",
    "  return BeautifulSoup(result.content, \"html.parser\") \n",
    "\n",
    "def flatten(ls:list): \n",
    "  \"\"\"Flattens/unnests a list of lists by one layer\"\"\"\n",
    "  return list(itertools.chain.from_iterable(ls)) \n",
    "\n",
    "def ff_list(ls:list) -> list:\n",
    "  \"\"\"Forward fill the values in a list\"\"\"\n",
    "  for i in range(len(ls)):\n",
    "    if not ls[i] and i > 0:\n",
    "        ls[i] = ls[i-1]\n",
    "  return ls\n",
    "\n",
    "## Specific Utilities\n",
    "def get_nws_url(row:pd.Series) -> str:\n",
    "  \"\"\"\n",
    "  Get url for the next 48 hours of forecasts from latitude and longitude columns\n",
    "  \n",
    "  Args: \n",
    "  row (pd.Series): The current row of the dataframe\n",
    "\n",
    "  Returns: \n",
    "  url (str): The url for the next 48 hours of forecasts\n",
    "  \"\"\"\n",
    "  lat, lon = row[\"latitude\"], row[\"longitude\"]\n",
    "  url = f\"https://forecast.weather.gov/MapClick.php?w0=t&w1=td&w2=wc&w3=sfcwind&w3u=1&w4=sky&w5=pop&w6=rh&w7=rain&w8=thunder&w9=snow&w10=fzg&w11=sleet&w12=fog&AheadHour=0&Submit=Submit&FcstType=digital&textField1={lat}&textField2={lon}&site=all&unit=0&dd=&bw=&menu=1\"\n",
    "  return url\n",
    "\n",
    "def get_last_update(soup:BeautifulSoup) -> dt.datetime:\n",
    "  \"\"\"\n",
    "  Find the \"Last Updated\" value from a BeautifulSoup object, transform to a datetime in AKST\n",
    "\n",
    "  Args:\n",
    "  soup (BeautifulSoup): A Beautiful Soup representation of a particular NWS forecast page\n",
    "\n",
    "  Returns: \n",
    "  last_update_dt (datetime): Datetime representation of time page was last updated (AKST)\n",
    "  \"\"\"\n",
    "  last_update_tag = soup.find('td', string=lambda text: text and 'Last Update:' in text)\n",
    "  last_update_text = re.sub(\"Last Update: |\\s(?=pm)|AKST |,\", \"\", last_update_tag.getText())\n",
    "  last_update_dt = dt.datetime.strptime(last_update_text, \"%I:%M%p %b %d %Y\")\n",
    "  return last_update_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Core helper functions\n",
    "def extract_table_data(soup:BeautifulSoup, location:str) -> list:\n",
    "  \"\"\"\n",
    "  Extracts 48hr forecast table data from a Beautiful Soup object as a list of lists\n",
    "\n",
    "  Args: \n",
    "  table_records (list): List of <tr> elements containing NWS forecast data\n",
    "\n",
    "  location (str): The name of the place the forecast is for; used for filling out added \"location\" column \n",
    "\n",
    "  Returns:\n",
    "  table (list): List of lists containing table data \n",
    "  \"\"\"\n",
    "  table_records = soup.find_all(\"table\")[5].find_all(\"tr\")\n",
    "\n",
    "  colspan = table_records[0] # 48hr data is divided into two tables by two colspan elements\n",
    "  table = [tr for  tr in table_records if tr != colspan] # vertically concat tables by removing colspan elements\n",
    "\n",
    "  table = [[ele.getText() for ele in tr.find_all(\"font\")] for tr in table] \n",
    "\n",
    "  # Add location column \n",
    "  location_col = ['location']\n",
    "  location_col.extend([location]*24) # fill out to match length of other columns\n",
    "  table.insert(1, location_col)  # for first half of table\n",
    "  table.insert(19, location_col) # for second half of table\n",
    "\n",
    "  # Add last_update_nws column \n",
    "  last_update_nws = ['last_update_nws']\n",
    "  last_update_nws.extend([get_last_update(soup)] * 24)\n",
    "  table.insert(1, last_update_nws)\n",
    "  table.insert(19, last_update_nws) \n",
    "\n",
    "  return table\n",
    "\n",
    "def transpose_as_dict(table:list) -> dict:\n",
    "  \"\"\"\n",
    "  Takes the list of lists generated by extract_table_data() and transposes it (flip orientation) by casting as a dictionary\n",
    "  \n",
    "  Args:\n",
    "  table (list): list of lists of columnar data generated by extract_table_data()\n",
    "\n",
    "  Returns: \n",
    "  data_map (dict): Dictionary representation of table, transposed and ready to be made into a dataframe\n",
    "  \"\"\"\n",
    "  data_map = {}\n",
    "  for col in table: # Table is still \"landscape-oriented\"\n",
    "    if col[0] not in data_map.keys(): # cols from first half of table\n",
    "      data_map[col[0]] = col[1:]\n",
    "    else: # cols from second half\n",
    "      data_map[col[0]].extend(col[1:])\n",
    "  data_map['Date'] = ff_list(data_map['Date'])\n",
    "  return data_map\n",
    "\n",
    "def transform_df(fcast_dict:dict) -> pd.DataFrame: \n",
    "  \"\"\"\n",
    "  Cast dictionary from transpose_as_dict() to a dataframe and transform\n",
    "\n",
    "  Args: \n",
    "  table (list)\n",
    "  \"\"\"\n",
    "  # Create dataframe\n",
    "  df = pd.DataFrame(fcast_dict)\n",
    "  \n",
    "  # Edit column headers \n",
    "  df.columns = [col.lower() for col in df.columns] \n",
    "  df.rename(columns=lambda x: re.sub('°|\\(|\\)', '', x), inplace=True)\n",
    "  df.rename(columns=lambda x: re.sub('%', 'pct', x), inplace=True)\n",
    "  df.rename(columns=lambda x: re.sub(' ', '_', x.strip()), inplace=True)\n",
    "  \n",
    "  # Replace missing value indicators with Nan\n",
    "  df.replace({'':np.NaN, '--':np.NaN}, inplace=True)\n",
    "  \n",
    "  ## Datetime Transformations\n",
    "  cur_year = dt.datetime.now().year\n",
    "  dt_strings = df['date'] + '/' + str(cur_year) + ' ' + df['hour_akst'] + ':00 AKST'\n",
    "  # Local time (AKST)\n",
    "  df['lst_datetime'] = pd.to_datetime(dt_strings, format='%m/%d/%Y %H:%M AKST')\n",
    "  # UTC time\n",
    "  akst_offset = dt.timedelta(hours=9)\n",
    "  df['utc_datetime'] = df['lst_datetime'] + akst_offset\n",
    "  # isDaytime\n",
    "  \n",
    "  ## Reorder columns \n",
    "  col_names = ['location', 'utc_datetime', 'lst_datetime'] + list(df.columns[4:-2]) + ['last_update_nws']\n",
    "  df = df[col_names]\n",
    "\n",
    "\n",
    "  return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "nws_urls = locations_df.apply(get_nws_url, axis=1)\n",
    "url_map = dict(zip(locations_df['station_location'], nws_urls))\n",
    "\n",
    "combined_table = []\n",
    "for location, url in url_map.items():\n",
    "  soup_list = [get_soup(url + f\"&AheadHour={hr}\") for hr in (0,48,96)]\n",
    "  table_list = flatten([extract_table_data(soup, location) for soup in soup_list])\n",
    "  combined_table.extend(table_list)\n",
    "  break\n",
    "my_dict = transpose_as_dict(combined_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "df = pd.DataFrame(my_dict)\n",
    "\n",
    "# Edit column headers \n",
    "df.columns = [col.lower() for col in df.columns] \n",
    "df.rename(columns=lambda x: re.sub('°|\\(|\\)', '', x), inplace=True)\n",
    "df.rename(columns=lambda x: re.sub('%', 'pct', x), inplace=True)\n",
    "df.rename(columns=lambda x: re.sub(' ', '_', x.strip()), inplace=True)\n",
    "\n",
    "# Replace missing value indicators with Nan\n",
    "df.replace({'':np.NaN, '--':np.NaN}, inplace=True)\n",
    "\n",
    "## Datetime Transformations\n",
    "cur_year = dt.datetime.now().year\n",
    "dt_strings = df['date'] + '/' + str(cur_year) + ' ' + df['hour_akst'] + ':00 AKST'\n",
    "# Local time (AKST)\n",
    "df['lst_datetime'] = pd.to_datetime(dt_strings, format='%m/%d/%Y %H:%M AKST')\n",
    "# UTC time\n",
    "akst_offset = dt.timedelta(hours=9)\n",
    "df['utc_datetime'] = df['lst_datetime'] + akst_offset\n",
    "# is_daytime\n",
    "df['is_daytime'] = np.where(df['lst_datetime'].time())\n",
    "\n",
    "\n",
    "## Reorder columns \n",
    "col_names = ['location', 'utc_datetime', 'lst_datetime'] + list(df.columns[4:-2]) + ['last_update_nws']\n",
    "df = df[col_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.time(20, 0)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lst_datetime'][0].time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.) Uploading the Data \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70623b801652781c2389d9f74154af1ef3dd8a50bfe8b7cd6824c1648ddc5ad0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
